<!doctype html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>Crawling</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="res/styles3.css" type="text/css" />
</head>
<body>
<div class='page'><strong><h1># Crawling</h1></strong><br />A website crawler will follow all of the clickable links in a website&#39;s source code and produce a map of the website for you. Pretty useful.<br /><br /><strong><h2>## Tools</h2></strong><br /><strong><h3>### wget</h3></strong><br /><code>wget -r -m -nv http://www.example.org/</code><br /><code>-r</code> recursive<br /><code>-m</code> turns on recursion, time-stamping, sets infinite recursion depth<br /><code>-nv</code> no verbose (but not completely quiet)<br /><code>-q</code> quiet<br /><br /><code>--no-check-certificate</code> to skip verifying the SSL certificate<br /><br /><div class="codebox"><div class="codebox">root@kali:~#&nbsp;wget&nbsp;-r&nbsp;-m&nbsp;-nv&nbsp;http://www.example.org/<br />02:27:54&nbsp;URL:http://www.example.org/&nbsp;[3558]&nbsp;-&gt;<br />&quot;www.example.org/index.html&quot;&nbsp;[1]<br />02:27:54&nbsp;URL:http://www.example.org/index.jsp?page=falls.shtml&nbsp;[1124]&nbsp;-&gt;<br />&quot;www.example.org/index.jsp?page=falls.shtml&quot;&nbsp;[1]<br />02:27:54&nbsp;URL:http://www.example.org/images/falls.jpg&nbsp;[81279/81279]&nbsp;-&gt;<br />&quot;www.example.org/images/falls.jpg&quot;&nbsp;[1]<br />[...]</div></div><br /><br />Use <code>tree</code> to view the scraped content<br /><code>tree</code><br /><br /><strong><h3>### skipfish</h3></strong><br /><a href="https://tools.kali.org/web-applications/skipfish">https://tools.kali.org/web-applications/skipfish</a><br />Skipfish is a &quot;web app security reconnaissance tool&quot; developed by Google. <br />It carries out a recursive crawl and dictionary-based probe of the site and produces a sitemap.<br /><br /><code>mkdir skipfish_results; skipfish -o skipfish_results </code><a href="http://www.target.com">http://www.target.com</a><br /><br /><strong><h3>### Nmap http-sitemap-generator Script</h3></strong><br />I advise making a directory to store the results before you run the script.<br /><code>nmap -p &lt;port&gt; -Pn --script=http-sitemap-generator 10.10.10.45</code><br /><br /><strong><h3>### cewl</h3></strong><br /><code>cewl</code> crawls a website and generates a wordlist to be used for further directory discovery or password bruteforcing.<br />The only place I&#39;ve found it relevant for is OSCP, but it&#39;s probably useful in the real world too.<br /><br /><code>cewl http://10.11.1.39/otrs/installer.pl &gt; cewl.txt</code><br /><br /><strong><h2>## How to use the crawled data</h2></strong><br /><strong><h3>### Identify Server Technologies</h3></strong><br />Using the scraped info, you can identify technologies on the server<br /><br /><a href=""><img src="images/212-1.png" alt="images/212-1.png" /></a><br /><br /><strong><h3>### Grep for useful data</h3></strong><br />You can manually review or <code>grep</code> the crawled web page source code to identify useful data<br />e.g.<br /><div class="codebox"><div class="codebox">root@kali:~#&nbsp;cd&nbsp;www.example.org<br />root@kali:~#&nbsp;grep&nbsp;–r&nbsp;–i&nbsp;&#39;type=hidden&#39;&nbsp;*<br />index.jsp?page=falls.shtml:&lt;INPUT&nbsp;TYPE=HIDDEN&nbsp;NAME=_CONFFILE&nbsp;VALUE=&quot;cart.ini&quot;&gt;<br />index.jsp?page=falls.shtml:&lt;INPUT&nbsp;TYPE=HIDDEN&nbsp;NAME=_ACTION&nbsp;VALUE=&quot;ADD&quot;&gt;<br />index.jsp?page=falls.shtml:&lt;INPUT&nbsp;TYPE=HIDDEN&nbsp;NAME=_PCODE&nbsp;VALUE=&quot;88-001&quot;&gt;</div></div><br /><br /><strong>#### JavaScript</strong><br />Search for &lt;script tags<br /><code>grep –r –i &#39;&lt;script&#39; *</code><br /><br /><strong>#### Email addresses </strong><br />Search for <code>@</code><br /><code>grep –r &#39;@&#39; *</code><br /><br /><strong>#### Hidden form fields </strong><br />Search for TYPE=HIDDEN<br /><code>grep –r –i &#39;type=hidden&#39; *</code><br /><br /><strong>#### HTML comments </strong><br />Search for comments<br /><code>grep –r &#39;&lt;!--&#39; *</code><br /><br /><strong>#### Hyperlinks </strong><br />Search for HREF or ACTION<br /><code>grep –r –i &#39;href=|action=&#39; *</code><br /><br /><strong>#### Metadata</strong><br />Search &lt;meta tags<br /><code>grep –r –i &#39;&lt;meta&#39; *</code></div>
</body>
</html>
